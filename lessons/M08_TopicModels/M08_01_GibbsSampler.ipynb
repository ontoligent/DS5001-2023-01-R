{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Metadata\n",
    "\n",
    "```yaml\n",
    "Course:    DS 5001 \n",
    "Module:    08 Lab\n",
    "Topic:     Gibbs Sampler\n",
    "Author:    R.C. Alvarado\n",
    "Date:      03 March 2023 (revised)\n",
    "```\n",
    "**Purpose:** We develop a simple topic modeler using collapsed Gibbs sample as described by [Griffiths and Steyvers (2004)](https://collab.its.virginia.edu/access/content/group/b9e58ce7-0f44-48fe-9861-b7a7657f551a/Articles/sciencetopics.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert F1 Corpus \n",
    "\n",
    "We want to convert any given F1 corpus (DOC) into unannotated TOKEN and VOCAB tables.\n",
    "\n",
    "This is so we can work with ad hoc training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "\n",
    "    def __init__(self, doc_list:list, doc_col='doc_str'):\n",
    "        \"Create DOC table from F1 list\"\n",
    "        self.DOC = pd.DataFrame(doc_list, columns=[doc_col])\n",
    "        self.DOC.index.name = 'doc_id'\n",
    "        self.stop_words = set(stopwords.words('english')) \n",
    "        \n",
    "    def convert_corpus(self):        \n",
    "        \"Convert raw docs into TOKEN and BOW tables\"\n",
    "        tokens = []\n",
    "        for i, row in self.DOC.iterrows():\n",
    "            for j, token in enumerate(row.doc_str.split()):\n",
    "                term_str = re.sub(r'[\\W_]+', '', token).lower()\n",
    "                if term_str not in self.stop_words:\n",
    "                    tokens.append((i, j, term_str))\n",
    "        self.TOKEN = pd.DataFrame(tokens, columns=['doc_id','token_num','term_str'])\\\n",
    "            .set_index(['doc_id','token_num'])\n",
    "        self.BOW = self.TOKEN.groupby(['doc_id','term_str']).term_str.count().to_frame('n')\n",
    "        return self\n",
    "        \n",
    "    def extract_vocab(self):\n",
    "        \"Extract vocabulary\"\n",
    "        self.VOCAB = self.TOKEN.term_str.value_counts().to_frame('n')\n",
    "        self.VOCAB.index.name = 'term_str'   \n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_docs = \"\"\"\n",
    "I ate a banana and a spinach smoothie for breakfast.\n",
    "I like to eat broccoli and bananas.\n",
    "Chinchillas and kittens are cute.\n",
    "My sister adopted a kitten yesterday.\n",
    "Look at this cute hamster munching on a piece of broccoli.\n",
    "\"\"\".split(\"\\n\")[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = Corpus(raw_docs).convert_corpus().extract_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>ate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothie</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spinach</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>bananas</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broccoli</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>chinchillas</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cute</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kittens</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>adopted</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitten</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sister</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yesterday</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">4</th>\n",
       "      <th>broccoli</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cute</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamster</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>munching</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n\n",
       "doc_id term_str      \n",
       "0      ate          1\n",
       "       banana       1\n",
       "       breakfast    1\n",
       "       smoothie     1\n",
       "       spinach      1\n",
       "1      bananas      1\n",
       "       broccoli     1\n",
       "       eat          1\n",
       "       like         1\n",
       "2      chinchillas  1\n",
       "       cute         1\n",
       "       kittens      1\n",
       "3      adopted      1\n",
       "       kitten       1\n",
       "       sister       1\n",
       "       yesterday    1\n",
       "4      broccoli     1\n",
       "       cute         1\n",
       "       hamster      1\n",
       "       look         1\n",
       "       munching     1\n",
       "       piece        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus1.BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs Sampler\n",
    "\n",
    "We sample each document and word combination in the BOW table. In each case,\n",
    "we are looking for two values:\n",
    "\n",
    "* the topic with which a word has been most frequently labeled\n",
    "* the topic with which the document has the most labeled words\n",
    "\n",
    "We combine these values in order to align the label of the current word with the rest of the data.\\\n",
    "If a the topic is highly associated with both the word and the document, then that topic will get a high value.\n",
    "\n",
    "Note that all that is going on here is a sorting operation -- the random assignment does not predict anything.\\\n",
    "Instead, we are just gathering words under topics and topics under documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Darling 2011:**\n",
    "<hr />\n",
    "<div style=\"float:left;\">\n",
    "<img src=\"images/gibbs-algo-text.png\" width=\"650px\" />\n",
    "<img src=\"images/gibbs-algo.png\" width=\"650px\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GibbsSampler:\n",
    "\n",
    "    def __init__(self, n_topics=10, iters=100, a = 1, b = .1):\n",
    "\n",
    "        # Map arguments\n",
    "        self.n_topics = n_topics\n",
    "        self.iters = iters\n",
    "        self.a = a\n",
    "        self.b = b \n",
    "        \n",
    "        # Define topic table\n",
    "        topic_names = [f\"T{str(t).zfill(len(str(self.n_topics)))}\" for t in range(self.n_topics)]\n",
    "        self.TOPIC = pd.DataFrame({'top_terms':'TBD'}, index=topic_names)\n",
    "        self.TOPIC.index.name = 'topic_id'\n",
    "\n",
    "    def add_corpus(self, corpus:Corpus):\n",
    "        \n",
    "        # Copy BOW and assign random topics        \n",
    "        self.BOW = corpus.BOW.copy()\n",
    "        self.BOW['topic_id'] = self.TOPIC.sample(len(self.BOW), replace=True).index\n",
    "        \n",
    "        # Get vocab length\n",
    "        self.VOCAB = corpus.VOCAB\n",
    "        self.W = self.VOCAB.shape[0]       \n",
    "        \n",
    "        return self\n",
    "            \n",
    "    def compute_topics(self):\n",
    "\n",
    "        # Create count tables\n",
    "        self.THETA = self.BOW.value_counts(['doc_id', 'topic_id']).unstack().fillna(0)\n",
    "        self.PHI = self.BOW.value_counts(['topic_id', 'term_str']).unstack().fillna(0)\n",
    "        self.TOPIC['n'] = self.BOW.value_counts('topic_id').fillna(0)\n",
    "        \n",
    "        # Iterate \n",
    "        for i in tqdm(range(self.iters)):  \n",
    "            \n",
    "            # Estimage topic per word\n",
    "            for doc_id, term_str in self.BOW.index:\n",
    "            \n",
    "                # Get the currenttly assigned topic\n",
    "                z = self.BOW.loc[(doc_id, term_str)].topic_id\n",
    "\n",
    "                # ... and remove from counts\n",
    "                self.THETA.loc[doc_id, z] -= 1\n",
    "                self.PHI.loc[z, term_str] -= 1\n",
    "                self.TOPIC.loc[z, 'n']    -= 1\n",
    "                                \n",
    "                # Estimate probability of new topic for this word\n",
    "                # A, B, and C are each topic vectors with counts in a given context\n",
    "                A = self.THETA.loc[doc_id] + self.a # Context = document\n",
    "                B = self.PHI[term_str] + self.b # Context = vocab\n",
    "                AP = A.T / A.T.sum()\n",
    "                BP = B.T / B.T.sum()\n",
    "                PZ = AP * BP\n",
    "\n",
    "                # Darling 2011\n",
    "                # C = self.TOPIC['n'] + (self.b * self.W) # Context = corpus\n",
    "                # PZ = A * (B/C)\n",
    "                \n",
    "                # Sample from new distribution and reassign\n",
    "                z2 = PZ.sample(weights=PZ).index[0]\n",
    "                self.THETA.loc[doc_id, z2] += 1\n",
    "                self.PHI.loc[z2, term_str] += 1\n",
    "                self.TOPIC.loc[z2, 'n']    += 1\n",
    "                self.BOW.loc[(doc_id, term_str), 'topic_id'] = z2\n",
    "                \n",
    "            # Compute perplexity of each iteration\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def get_top_terms(self):\n",
    "        # Get top words for each topic\n",
    "        for topic_id in self.TOPIC.index:\n",
    "            self.TOPIC.loc[topic_id, 'top_terms'] = ' '.join(self.PHI.loc[topic_id, self.PHI.loc[topic_id] > 0].index.values)\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_all(f1_list:[], k=4, iters=100):\n",
    "    corpus = Corpus(f1_list).convert_corpus().extract_vocab()\n",
    "    model = GibbsSampler(n_topics=k, iters=iters, a=1, b=1).add_corpus(corpus).compute_topics().get_top_terms()\n",
    "    return corpus, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Demo 1\n",
    "\n",
    "We use a toy example to see if the method works.\\\n",
    "Because our codd is not vert efficient, we just "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "A small F1 corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_docs = \"\"\"\n",
    "I ate a banana and a spinach smoothie for breakfast.\n",
    "I like to eat broccoli and bananas.\n",
    "Chinchillas and kittens are cute.\n",
    "My sister adopted a kitten yesterday.\n",
    "Look at this cute hamster munching on a piece of broccoli.\n",
    "\"\"\".split(\"\\n\")[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 25.32it/s]\n"
     ]
    }
   ],
   "source": [
    "cp1, tm1 = do_all(raw_docs, k=5, iters=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_terms</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T0</th>\n",
       "      <td>breakfast broccoli cute yesterday</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1</th>\n",
       "      <td>ate cute kittens piece smoothie</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T2</th>\n",
       "      <td>adopted broccoli eat kitten sister spinach</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3</th>\n",
       "      <td>bananas chinchillas like munching</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T4</th>\n",
       "      <td>banana hamster look</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           top_terms  n\n",
       "topic_id                                               \n",
       "T0                 breakfast broccoli cute yesterday  4\n",
       "T1                   ate cute kittens piece smoothie  5\n",
       "T2        adopted broccoli eat kitten sister spinach  6\n",
       "T3                 bananas chinchillas like munching  4\n",
       "T4                               banana hamster look  3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm1.TOPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_56e05_row0_col1, #T_56e05_row0_col3, #T_56e05_row0_col5, #T_56e05_row1_col1, #T_56e05_row1_col3, #T_56e05_row2_col1, #T_56e05_row2_col2, #T_56e05_row2_col4, #T_56e05_row3_col1, #T_56e05_row4_col3, #T_56e05_row4_col4 {\n",
       "  background-color: #b4c4df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56e05_row0_col2, #T_56e05_row1_col4, #T_56e05_row4_col2, #T_56e05_row4_col5 {\n",
       "  background-color: #2685bb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56e05_row0_col4, #T_56e05_row1_col2, #T_56e05_row1_col5, #T_56e05_row2_col3, #T_56e05_row2_col5, #T_56e05_row3_col2, #T_56e05_row3_col4, #T_56e05_row3_col5, #T_56e05_row4_col1 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56e05_row3_col3 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_56e05\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_56e05_level0_col0\" class=\"col_heading level0 col0\" >doc_str</th>\n",
       "      <th id=\"T_56e05_level0_col1\" class=\"col_heading level0 col1\" >T0</th>\n",
       "      <th id=\"T_56e05_level0_col2\" class=\"col_heading level0 col2\" >T1</th>\n",
       "      <th id=\"T_56e05_level0_col3\" class=\"col_heading level0 col3\" >T2</th>\n",
       "      <th id=\"T_56e05_level0_col4\" class=\"col_heading level0 col4\" >T3</th>\n",
       "      <th id=\"T_56e05_level0_col5\" class=\"col_heading level0 col5\" >T4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >doc_id</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_56e05_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_56e05_row0_col0\" class=\"data row0 col0\" >I ate a banana and a spinach smoothie for breakfast.</td>\n",
       "      <td id=\"T_56e05_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_56e05_row0_col2\" class=\"data row0 col2\" >2</td>\n",
       "      <td id=\"T_56e05_row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "      <td id=\"T_56e05_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_56e05_row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56e05_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_56e05_row1_col0\" class=\"data row1 col0\" >I like to eat broccoli and bananas.</td>\n",
       "      <td id=\"T_56e05_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_56e05_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_56e05_row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "      <td id=\"T_56e05_row1_col4\" class=\"data row1 col4\" >2</td>\n",
       "      <td id=\"T_56e05_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56e05_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_56e05_row2_col0\" class=\"data row2 col0\" >Chinchillas and kittens are cute.</td>\n",
       "      <td id=\"T_56e05_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "      <td id=\"T_56e05_row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "      <td id=\"T_56e05_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "      <td id=\"T_56e05_row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "      <td id=\"T_56e05_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56e05_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_56e05_row3_col0\" class=\"data row3 col0\" >My sister adopted a kitten yesterday.</td>\n",
       "      <td id=\"T_56e05_row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "      <td id=\"T_56e05_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_56e05_row3_col3\" class=\"data row3 col3\" >3</td>\n",
       "      <td id=\"T_56e05_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_56e05_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56e05_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_56e05_row4_col0\" class=\"data row4 col0\" >Look at this cute hamster munching on a piece of broccoli.</td>\n",
       "      <td id=\"T_56e05_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_56e05_row4_col2\" class=\"data row4 col2\" >2</td>\n",
       "      <td id=\"T_56e05_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "      <td id=\"T_56e05_row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "      <td id=\"T_56e05_row4_col5\" class=\"data row4 col5\" >2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f91b7aec8b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp1.DOC.join(tm1.THETA.astype('int')).style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_documents = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]\n",
    "raw_docs2  = [' '.join(item) for item in some_documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [01:13<00:00,  6.76it/s]\n"
     ]
    }
   ],
   "source": [
    "cp2, tm2 = do_all(raw_docs2, k=10, iters=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_terms</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T00</th>\n",
       "      <td>big data hbase java languages learning postgre...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T01</th>\n",
       "      <td>data databases libsvm neural python support</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T02</th>\n",
       "      <td>c decision deep mysql statsmodels storm vector</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T03</th>\n",
       "      <td>artificial haskell neural probability python s...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T04</th>\n",
       "      <td>deep learning machine networks pandas postgres r</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T05</th>\n",
       "      <td>hadoop machines mapreduce nosql probability sc...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T06</th>\n",
       "      <td>data hbase java learning mathematics networks ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T07</th>\n",
       "      <td>big cassandra hbase learning machine mongodb s...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T08</th>\n",
       "      <td>artificial cassandra hadoop libsvm mongodb spa...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T09</th>\n",
       "      <td>intelligence java mahout numpy python r regres...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  top_terms   n\n",
       "topic_id                                                       \n",
       "T00       big data hbase java languages learning postgre...  11\n",
       "T01             data databases libsvm neural python support   6\n",
       "T02          c decision deep mysql statsmodels storm vector   9\n",
       "T03       artificial haskell neural probability python s...   6\n",
       "T04        deep learning machine networks pandas postgres r   7\n",
       "T05       hadoop machines mapreduce nosql probability sc...   6\n",
       "T06       data hbase java learning mathematics networks ...  12\n",
       "T07       big cassandra hbase learning machine mongodb s...   8\n",
       "T08       artificial cassandra hadoop libsvm mongodb spa...   7\n",
       "T09       intelligence java mahout numpy python r regres...  10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm2.TOPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b1d6a_row0_col1, #T_b1d6a_row0_col2, #T_b1d6a_row0_col3, #T_b1d6a_row0_col7, #T_b1d6a_row1_col1, #T_b1d6a_row1_col6, #T_b1d6a_row1_col7, #T_b1d6a_row1_col8, #T_b1d6a_row1_col9, #T_b1d6a_row2_col3, #T_b1d6a_row2_col4, #T_b1d6a_row2_col5, #T_b1d6a_row3_col2, #T_b1d6a_row3_col5, #T_b1d6a_row3_col7, #T_b1d6a_row3_col8, #T_b1d6a_row3_col10, #T_b1d6a_row4_col3, #T_b1d6a_row4_col7, #T_b1d6a_row5_col1, #T_b1d6a_row5_col3, #T_b1d6a_row5_col4, #T_b1d6a_row5_col7, #T_b1d6a_row6_col4, #T_b1d6a_row6_col7, #T_b1d6a_row7_col4, #T_b1d6a_row7_col6, #T_b1d6a_row7_col10, #T_b1d6a_row8_col1, #T_b1d6a_row8_col2, #T_b1d6a_row8_col3, #T_b1d6a_row8_col4, #T_b1d6a_row8_col10, #T_b1d6a_row9_col8, #T_b1d6a_row10_col3, #T_b1d6a_row10_col7, #T_b1d6a_row10_col8, #T_b1d6a_row11_col1, #T_b1d6a_row11_col3, #T_b1d6a_row11_col5, #T_b1d6a_row11_col6, #T_b1d6a_row11_col9, #T_b1d6a_row11_col10, #T_b1d6a_row12_col4, #T_b1d6a_row13_col1, #T_b1d6a_row13_col2, #T_b1d6a_row13_col3, #T_b1d6a_row13_col5, #T_b1d6a_row13_col9, #T_b1d6a_row14_col1, #T_b1d6a_row14_col3, #T_b1d6a_row14_col6 {\n",
       "  background-color: #b4c4df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1d6a_row0_col4, #T_b1d6a_row0_col5, #T_b1d6a_row0_col6, #T_b1d6a_row0_col10, #T_b1d6a_row1_col2, #T_b1d6a_row1_col3, #T_b1d6a_row1_col4, #T_b1d6a_row1_col5, #T_b1d6a_row1_col10, #T_b1d6a_row2_col1, #T_b1d6a_row2_col2, #T_b1d6a_row2_col6, #T_b1d6a_row2_col7, #T_b1d6a_row2_col8, #T_b1d6a_row2_col9, #T_b1d6a_row3_col1, #T_b1d6a_row3_col3, #T_b1d6a_row3_col4, #T_b1d6a_row3_col6, #T_b1d6a_row3_col9, #T_b1d6a_row4_col1, #T_b1d6a_row4_col2, #T_b1d6a_row4_col4, #T_b1d6a_row4_col5, #T_b1d6a_row4_col6, #T_b1d6a_row4_col10, #T_b1d6a_row5_col2, #T_b1d6a_row5_col5, #T_b1d6a_row5_col6, #T_b1d6a_row5_col8, #T_b1d6a_row5_col9, #T_b1d6a_row6_col2, #T_b1d6a_row6_col3, #T_b1d6a_row6_col5, #T_b1d6a_row6_col6, #T_b1d6a_row6_col8, #T_b1d6a_row6_col9, #T_b1d6a_row6_col10, #T_b1d6a_row7_col1, #T_b1d6a_row7_col2, #T_b1d6a_row7_col3, #T_b1d6a_row7_col7, #T_b1d6a_row7_col8, #T_b1d6a_row7_col9, #T_b1d6a_row8_col5, #T_b1d6a_row8_col6, #T_b1d6a_row8_col8, #T_b1d6a_row8_col9, #T_b1d6a_row9_col2, #T_b1d6a_row9_col3, #T_b1d6a_row9_col4, #T_b1d6a_row9_col5, #T_b1d6a_row9_col7, #T_b1d6a_row9_col9, #T_b1d6a_row9_col10, #T_b1d6a_row10_col1, #T_b1d6a_row10_col2, #T_b1d6a_row10_col4, #T_b1d6a_row10_col5, #T_b1d6a_row10_col6, #T_b1d6a_row10_col9, #T_b1d6a_row10_col10, #T_b1d6a_row11_col2, #T_b1d6a_row11_col4, #T_b1d6a_row11_col7, #T_b1d6a_row11_col8, #T_b1d6a_row12_col1, #T_b1d6a_row12_col2, #T_b1d6a_row12_col3, #T_b1d6a_row12_col5, #T_b1d6a_row12_col6, #T_b1d6a_row12_col8, #T_b1d6a_row12_col9, #T_b1d6a_row12_col10, #T_b1d6a_row13_col4, #T_b1d6a_row13_col6, #T_b1d6a_row13_col7, #T_b1d6a_row13_col8, #T_b1d6a_row13_col10, #T_b1d6a_row14_col4, #T_b1d6a_row14_col5, #T_b1d6a_row14_col7, #T_b1d6a_row14_col8, #T_b1d6a_row14_col9, #T_b1d6a_row14_col10 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1d6a_row0_col8, #T_b1d6a_row0_col9, #T_b1d6a_row4_col8, #T_b1d6a_row4_col9, #T_b1d6a_row6_col1, #T_b1d6a_row9_col1, #T_b1d6a_row9_col6, #T_b1d6a_row12_col7, #T_b1d6a_row14_col2 {\n",
       "  background-color: #2685bb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1d6a_row2_col10, #T_b1d6a_row5_col10, #T_b1d6a_row7_col5, #T_b1d6a_row8_col7 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b1d6a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b1d6a_level0_col0\" class=\"col_heading level0 col0\" >doc_str</th>\n",
       "      <th id=\"T_b1d6a_level0_col1\" class=\"col_heading level0 col1\" >T00</th>\n",
       "      <th id=\"T_b1d6a_level0_col2\" class=\"col_heading level0 col2\" >T01</th>\n",
       "      <th id=\"T_b1d6a_level0_col3\" class=\"col_heading level0 col3\" >T02</th>\n",
       "      <th id=\"T_b1d6a_level0_col4\" class=\"col_heading level0 col4\" >T03</th>\n",
       "      <th id=\"T_b1d6a_level0_col5\" class=\"col_heading level0 col5\" >T04</th>\n",
       "      <th id=\"T_b1d6a_level0_col6\" class=\"col_heading level0 col6\" >T05</th>\n",
       "      <th id=\"T_b1d6a_level0_col7\" class=\"col_heading level0 col7\" >T06</th>\n",
       "      <th id=\"T_b1d6a_level0_col8\" class=\"col_heading level0 col8\" >T07</th>\n",
       "      <th id=\"T_b1d6a_level0_col9\" class=\"col_heading level0 col9\" >T08</th>\n",
       "      <th id=\"T_b1d6a_level0_col10\" class=\"col_heading level0 col10\" >T09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >doc_id</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b1d6a_row0_col0\" class=\"data row0 col0\" >Hadoop Big Data HBase Java Spark Storm Cassandra</td>\n",
       "      <td id=\"T_b1d6a_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_b1d6a_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "      <td id=\"T_b1d6a_row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "      <td id=\"T_b1d6a_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_b1d6a_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_b1d6a_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_b1d6a_row0_col7\" class=\"data row0 col7\" >1</td>\n",
       "      <td id=\"T_b1d6a_row0_col8\" class=\"data row0 col8\" >2</td>\n",
       "      <td id=\"T_b1d6a_row0_col9\" class=\"data row0 col9\" >2</td>\n",
       "      <td id=\"T_b1d6a_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b1d6a_row1_col0\" class=\"data row1 col0\" >NoSQL MongoDB Cassandra HBase Postgres</td>\n",
       "      <td id=\"T_b1d6a_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_b1d6a_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_b1d6a_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_b1d6a_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_b1d6a_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_b1d6a_row1_col6\" class=\"data row1 col6\" >1</td>\n",
       "      <td id=\"T_b1d6a_row1_col7\" class=\"data row1 col7\" >1</td>\n",
       "      <td id=\"T_b1d6a_row1_col8\" class=\"data row1 col8\" >1</td>\n",
       "      <td id=\"T_b1d6a_row1_col9\" class=\"data row1 col9\" >1</td>\n",
       "      <td id=\"T_b1d6a_row1_col10\" class=\"data row1 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b1d6a_row2_col0\" class=\"data row2 col0\" >Python scikit-learn scipy numpy statsmodels pandas</td>\n",
       "      <td id=\"T_b1d6a_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_b1d6a_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_b1d6a_row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "      <td id=\"T_b1d6a_row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "      <td id=\"T_b1d6a_row2_col5\" class=\"data row2 col5\" >1</td>\n",
       "      <td id=\"T_b1d6a_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "      <td id=\"T_b1d6a_row2_col7\" class=\"data row2 col7\" >0</td>\n",
       "      <td id=\"T_b1d6a_row2_col8\" class=\"data row2 col8\" >0</td>\n",
       "      <td id=\"T_b1d6a_row2_col9\" class=\"data row2 col9\" >0</td>\n",
       "      <td id=\"T_b1d6a_row2_col10\" class=\"data row2 col10\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b1d6a_row3_col0\" class=\"data row3 col0\" >R Python statistics regression probability</td>\n",
       "      <td id=\"T_b1d6a_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_b1d6a_row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "      <td id=\"T_b1d6a_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_b1d6a_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_b1d6a_row3_col5\" class=\"data row3 col5\" >1</td>\n",
       "      <td id=\"T_b1d6a_row3_col6\" class=\"data row3 col6\" >0</td>\n",
       "      <td id=\"T_b1d6a_row3_col7\" class=\"data row3 col7\" >1</td>\n",
       "      <td id=\"T_b1d6a_row3_col8\" class=\"data row3 col8\" >1</td>\n",
       "      <td id=\"T_b1d6a_row3_col9\" class=\"data row3 col9\" >0</td>\n",
       "      <td id=\"T_b1d6a_row3_col10\" class=\"data row3 col10\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b1d6a_row4_col0\" class=\"data row4 col0\" >machine learning regression decision trees libsvm</td>\n",
       "      <td id=\"T_b1d6a_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_b1d6a_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_b1d6a_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "      <td id=\"T_b1d6a_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "      <td id=\"T_b1d6a_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_b1d6a_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_b1d6a_row4_col7\" class=\"data row4 col7\" >1</td>\n",
       "      <td id=\"T_b1d6a_row4_col8\" class=\"data row4 col8\" >2</td>\n",
       "      <td id=\"T_b1d6a_row4_col9\" class=\"data row4 col9\" >2</td>\n",
       "      <td id=\"T_b1d6a_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b1d6a_row5_col0\" class=\"data row5 col0\" >Python R Java C++ Haskell programming languages</td>\n",
       "      <td id=\"T_b1d6a_row5_col1\" class=\"data row5 col1\" >1</td>\n",
       "      <td id=\"T_b1d6a_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "      <td id=\"T_b1d6a_row5_col3\" class=\"data row5 col3\" >1</td>\n",
       "      <td id=\"T_b1d6a_row5_col4\" class=\"data row5 col4\" >1</td>\n",
       "      <td id=\"T_b1d6a_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_b1d6a_row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "      <td id=\"T_b1d6a_row5_col7\" class=\"data row5 col7\" >1</td>\n",
       "      <td id=\"T_b1d6a_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "      <td id=\"T_b1d6a_row5_col9\" class=\"data row5 col9\" >0</td>\n",
       "      <td id=\"T_b1d6a_row5_col10\" class=\"data row5 col10\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b1d6a_row6_col0\" class=\"data row6 col0\" >statistics probability mathematics theory</td>\n",
       "      <td id=\"T_b1d6a_row6_col1\" class=\"data row6 col1\" >2</td>\n",
       "      <td id=\"T_b1d6a_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_b1d6a_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_b1d6a_row6_col4\" class=\"data row6 col4\" >1</td>\n",
       "      <td id=\"T_b1d6a_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_b1d6a_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "      <td id=\"T_b1d6a_row6_col7\" class=\"data row6 col7\" >1</td>\n",
       "      <td id=\"T_b1d6a_row6_col8\" class=\"data row6 col8\" >0</td>\n",
       "      <td id=\"T_b1d6a_row6_col9\" class=\"data row6 col9\" >0</td>\n",
       "      <td id=\"T_b1d6a_row6_col10\" class=\"data row6 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b1d6a_row7_col0\" class=\"data row7 col0\" >machine learning scikit-learn Mahout neural networks</td>\n",
       "      <td id=\"T_b1d6a_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_b1d6a_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_b1d6a_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_b1d6a_row7_col4\" class=\"data row7 col4\" >1</td>\n",
       "      <td id=\"T_b1d6a_row7_col5\" class=\"data row7 col5\" >3</td>\n",
       "      <td id=\"T_b1d6a_row7_col6\" class=\"data row7 col6\" >1</td>\n",
       "      <td id=\"T_b1d6a_row7_col7\" class=\"data row7 col7\" >0</td>\n",
       "      <td id=\"T_b1d6a_row7_col8\" class=\"data row7 col8\" >0</td>\n",
       "      <td id=\"T_b1d6a_row7_col9\" class=\"data row7 col9\" >0</td>\n",
       "      <td id=\"T_b1d6a_row7_col10\" class=\"data row7 col10\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b1d6a_row8_col0\" class=\"data row8 col0\" >neural networks deep learning Big Data artificial intelligence</td>\n",
       "      <td id=\"T_b1d6a_row8_col1\" class=\"data row8 col1\" >1</td>\n",
       "      <td id=\"T_b1d6a_row8_col2\" class=\"data row8 col2\" >1</td>\n",
       "      <td id=\"T_b1d6a_row8_col3\" class=\"data row8 col3\" >1</td>\n",
       "      <td id=\"T_b1d6a_row8_col4\" class=\"data row8 col4\" >1</td>\n",
       "      <td id=\"T_b1d6a_row8_col5\" class=\"data row8 col5\" >0</td>\n",
       "      <td id=\"T_b1d6a_row8_col6\" class=\"data row8 col6\" >0</td>\n",
       "      <td id=\"T_b1d6a_row8_col7\" class=\"data row8 col7\" >3</td>\n",
       "      <td id=\"T_b1d6a_row8_col8\" class=\"data row8 col8\" >0</td>\n",
       "      <td id=\"T_b1d6a_row8_col9\" class=\"data row8 col9\" >0</td>\n",
       "      <td id=\"T_b1d6a_row8_col10\" class=\"data row8 col10\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b1d6a_row9_col0\" class=\"data row9 col0\" >Hadoop Java MapReduce Big Data</td>\n",
       "      <td id=\"T_b1d6a_row9_col1\" class=\"data row9 col1\" >2</td>\n",
       "      <td id=\"T_b1d6a_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_b1d6a_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_b1d6a_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_b1d6a_row9_col5\" class=\"data row9 col5\" >0</td>\n",
       "      <td id=\"T_b1d6a_row9_col6\" class=\"data row9 col6\" >2</td>\n",
       "      <td id=\"T_b1d6a_row9_col7\" class=\"data row9 col7\" >0</td>\n",
       "      <td id=\"T_b1d6a_row9_col8\" class=\"data row9 col8\" >1</td>\n",
       "      <td id=\"T_b1d6a_row9_col9\" class=\"data row9 col9\" >0</td>\n",
       "      <td id=\"T_b1d6a_row9_col10\" class=\"data row9 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b1d6a_row10_col0\" class=\"data row10 col0\" >statistics R statsmodels</td>\n",
       "      <td id=\"T_b1d6a_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "      <td id=\"T_b1d6a_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_b1d6a_row10_col3\" class=\"data row10 col3\" >1</td>\n",
       "      <td id=\"T_b1d6a_row10_col4\" class=\"data row10 col4\" >0</td>\n",
       "      <td id=\"T_b1d6a_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "      <td id=\"T_b1d6a_row10_col6\" class=\"data row10 col6\" >0</td>\n",
       "      <td id=\"T_b1d6a_row10_col7\" class=\"data row10 col7\" >1</td>\n",
       "      <td id=\"T_b1d6a_row10_col8\" class=\"data row10 col8\" >1</td>\n",
       "      <td id=\"T_b1d6a_row10_col9\" class=\"data row10 col9\" >0</td>\n",
       "      <td id=\"T_b1d6a_row10_col10\" class=\"data row10 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b1d6a_row11_col0\" class=\"data row11 col0\" >C++ deep learning artificial intelligence probability</td>\n",
       "      <td id=\"T_b1d6a_row11_col1\" class=\"data row11 col1\" >1</td>\n",
       "      <td id=\"T_b1d6a_row11_col2\" class=\"data row11 col2\" >0</td>\n",
       "      <td id=\"T_b1d6a_row11_col3\" class=\"data row11 col3\" >1</td>\n",
       "      <td id=\"T_b1d6a_row11_col4\" class=\"data row11 col4\" >0</td>\n",
       "      <td id=\"T_b1d6a_row11_col5\" class=\"data row11 col5\" >1</td>\n",
       "      <td id=\"T_b1d6a_row11_col6\" class=\"data row11 col6\" >1</td>\n",
       "      <td id=\"T_b1d6a_row11_col7\" class=\"data row11 col7\" >0</td>\n",
       "      <td id=\"T_b1d6a_row11_col8\" class=\"data row11 col8\" >0</td>\n",
       "      <td id=\"T_b1d6a_row11_col9\" class=\"data row11 col9\" >1</td>\n",
       "      <td id=\"T_b1d6a_row11_col10\" class=\"data row11 col10\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b1d6a_row12_col0\" class=\"data row12 col0\" >pandas R Python</td>\n",
       "      <td id=\"T_b1d6a_row12_col1\" class=\"data row12 col1\" >0</td>\n",
       "      <td id=\"T_b1d6a_row12_col2\" class=\"data row12 col2\" >0</td>\n",
       "      <td id=\"T_b1d6a_row12_col3\" class=\"data row12 col3\" >0</td>\n",
       "      <td id=\"T_b1d6a_row12_col4\" class=\"data row12 col4\" >1</td>\n",
       "      <td id=\"T_b1d6a_row12_col5\" class=\"data row12 col5\" >0</td>\n",
       "      <td id=\"T_b1d6a_row12_col6\" class=\"data row12 col6\" >0</td>\n",
       "      <td id=\"T_b1d6a_row12_col7\" class=\"data row12 col7\" >2</td>\n",
       "      <td id=\"T_b1d6a_row12_col8\" class=\"data row12 col8\" >0</td>\n",
       "      <td id=\"T_b1d6a_row12_col9\" class=\"data row12 col9\" >0</td>\n",
       "      <td id=\"T_b1d6a_row12_col10\" class=\"data row12 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b1d6a_row13_col0\" class=\"data row13 col0\" >databases HBase Postgres MySQL MongoDB</td>\n",
       "      <td id=\"T_b1d6a_row13_col1\" class=\"data row13 col1\" >1</td>\n",
       "      <td id=\"T_b1d6a_row13_col2\" class=\"data row13 col2\" >1</td>\n",
       "      <td id=\"T_b1d6a_row13_col3\" class=\"data row13 col3\" >1</td>\n",
       "      <td id=\"T_b1d6a_row13_col4\" class=\"data row13 col4\" >0</td>\n",
       "      <td id=\"T_b1d6a_row13_col5\" class=\"data row13 col5\" >1</td>\n",
       "      <td id=\"T_b1d6a_row13_col6\" class=\"data row13 col6\" >0</td>\n",
       "      <td id=\"T_b1d6a_row13_col7\" class=\"data row13 col7\" >0</td>\n",
       "      <td id=\"T_b1d6a_row13_col8\" class=\"data row13 col8\" >0</td>\n",
       "      <td id=\"T_b1d6a_row13_col9\" class=\"data row13 col9\" >1</td>\n",
       "      <td id=\"T_b1d6a_row13_col10\" class=\"data row13 col10\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d6a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b1d6a_row14_col0\" class=\"data row14 col0\" >libsvm regression support vector machines</td>\n",
       "      <td id=\"T_b1d6a_row14_col1\" class=\"data row14 col1\" >1</td>\n",
       "      <td id=\"T_b1d6a_row14_col2\" class=\"data row14 col2\" >2</td>\n",
       "      <td id=\"T_b1d6a_row14_col3\" class=\"data row14 col3\" >1</td>\n",
       "      <td id=\"T_b1d6a_row14_col4\" class=\"data row14 col4\" >0</td>\n",
       "      <td id=\"T_b1d6a_row14_col5\" class=\"data row14 col5\" >0</td>\n",
       "      <td id=\"T_b1d6a_row14_col6\" class=\"data row14 col6\" >1</td>\n",
       "      <td id=\"T_b1d6a_row14_col7\" class=\"data row14 col7\" >0</td>\n",
       "      <td id=\"T_b1d6a_row14_col8\" class=\"data row14 col8\" >0</td>\n",
       "      <td id=\"T_b1d6a_row14_col9\" class=\"data row14 col9\" >0</td>\n",
       "      <td id=\"T_b1d6a_row14_col10\" class=\"data row14 col10\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f91b7b33280>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp2.DOC.join(tm2.THETA.astype('int')).style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eta",
   "language": "python",
   "name": "eta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "183.817px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c3b963de08c47c3b6758389c5e0978ad73698a111eb508d4e16b558edb8f4cbf"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
