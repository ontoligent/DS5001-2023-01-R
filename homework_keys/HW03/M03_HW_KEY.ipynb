{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ai-gvPnADykO",
    "tags": []
   },
   "source": [
    "# Metadata\n",
    "\n",
    "```yaml\n",
    "Course: DS 5001 \n",
    "Module: 03: Homework KEY\n",
    "Topics: Inferring and Interpreting Language Models \n",
    "Author: R.C. Alvarado\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Use the the following libraries and source text to answer the questions in this assessment. \n",
    "  * `pg42324.txt`\n",
    "  * `textimporter.py`\n",
    "  * `langmod.py`\n",
    "\n",
    "Follow this pattern:\n",
    "* Create a new notebook for your work.\n",
    "* Parse the _Frankenstein_ text to generate TOKENS and VOCAB tables.\n",
    "* Create a list of sentences from the TOKENS table and a list of terms from the VOCAB table. \n",
    "* Pass the two lists to an `langmod.NgramCounter` object to generate ngram type tables and models, going up to the trigram level.\n",
    "* Write the code to answer the following questions:\n",
    "  1. List six words that precede the word \"monster,\" excluding stop words (and sentence boundary markers). Stop words include 'a', 'an', 'the', 'this', 'that', etc. Hint: use the `df.query()` method.  \n",
    "  2. List the following sentences in ascending order of bigram perpexity according to the language model generated from the text:\n",
    "    ```\n",
    "    The monster is on the ice.\n",
    "    Flowers are happy things.\n",
    "    I have never seen the aurora borealis.\n",
    "    He never knew the love of a family.\n",
    "    ```\n",
    "  3. Using the bigram model represented as a matrix, explore the relationship between bigram pairs using the following lists. Hint: use the `.unstack()` method on the feature `n` and then use `.loc[]` to select the first list from the index, and the second list from the columns.\n",
    "     1. `['he','she']` to select the indices.\n",
    "     2. `['said','heard']` to select the columns.\n",
    "  4. Generate 20 sentences using the `.generate_text()` method from the `langmod.NgramLanguageModel` class.\n",
    "  5. Compute the redundancy $R$ for each of the n-gram models using the MLE of the joint probability of each ngram type. In other words, for each model, just use the `.mle` feature as $p$ in computing $H = \\sum p(ng) \\log_2(1/p(ng))$. Does $R$ increase, decrease, or remain the same as the choice of n-gram increases in length? Hint: Remember that $R = 1 - \\frac{H}{H_{max}}$, where $H$ is the actual entropy of the model and $H_{max}$ is its maximum entropy. \n",
    "\n",
    "\n",
    "Hints:\n",
    "* You may use the libraries or cut-and-paste code from the relevant notebooks.\n",
    "* Use the `M03_LanguageModels.ipynb` to see how the objects from the libraries are used.\n",
    "* The story begins with the Preface.\n",
    "* Even though they are not called \"chapters,\" treat the Preface and Letters as chapters.\n",
    "* Don't worry about OOV words or creating and `<UNK>` term in your vocabulary.\n",
    "* You don't have to use the \"START OF PROJECT GUTENBERG ...\", etc., to clip the text. Find the lines where you think the text actually begins and ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = \"./\"\n",
    "local_lib = \"./\"\n",
    "src_file_path = f'{data_home}/pg42324.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(local_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textimporter import TextImporter\n",
    "from langmod import NgramCounter, NgramLanguageModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohco_pats = [\n",
    "    ('chap', r\"^(?:PREFACE|CHAPTER|LETTER)\\s\", 'm')\n",
    "]\n",
    "clip_pats = [\n",
    "    r\"^M\\. W\\. S\\.\\s*$\",\n",
    "    r\"^THE END\\.\\s*$\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "franky = TextImporter(src_file_path, ohco_pats=ohco_pats, clip_pats=clip_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing  .//pg42324.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^(?:PREFACE|CHAPTER|LETTER)\\s\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by delimitter [.?!;:]+\n",
      "Parsing OHCO level 3 token_num by delimitter [\\s',-]+\n"
     ]
    }
   ],
   "source": [
    "franky.import_source().parse_tokens().extract_vocab();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>_To</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Saville</td>\n",
       "      <td>saville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>_</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">82</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>10</th>\n",
       "      <td>lost</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>darkness</td>\n",
       "      <td>darkness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75721 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    token_str  term_str\n",
       "chap_id para_num sent_num token_num                    \n",
       "1       0        0        0               _To        to\n",
       "                          1               Mrs       mrs\n",
       "                 1        1           Saville   saville\n",
       "                          2           England   england\n",
       "                 2        0                 _          \n",
       "...                                       ...       ...\n",
       "28      82       1        10             lost      lost\n",
       "                          11               in        in\n",
       "                          12         darkness  darkness\n",
       "                          13              and       and\n",
       "                          14         distance  distance\n",
       "\n",
       "[75721 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franky.TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "      <th>i</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>4197</td>\n",
       "      <td>3</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>18.041696</td>\n",
       "      <td>4.173263</td>\n",
       "      <td>0.231312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2976</td>\n",
       "      <td>3</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>25.443884</td>\n",
       "      <td>4.669247</td>\n",
       "      <td>0.183512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>2852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037665</td>\n",
       "      <td>26.550140</td>\n",
       "      <td>4.730648</td>\n",
       "      <td>0.178178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>2647</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>28.606347</td>\n",
       "      <td>4.838263</td>\n",
       "      <td>0.169133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2101</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>36.040457</td>\n",
       "      <td>5.171545</td>\n",
       "      <td>0.143493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overweigh</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pledge</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salvation</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timorous</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinks</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6965 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              n  n_chars         p             s          i         h\n",
       "term_str                                                             \n",
       "the        4197        3  0.055427     18.041696   4.173263  0.231312\n",
       "and        2976        3  0.039302     25.443884   4.669247  0.183512\n",
       "i          2852        1  0.037665     26.550140   4.730648  0.178178\n",
       "of         2647        2  0.034957     28.606347   4.838263  0.169133\n",
       "to         2101        2  0.027747     36.040457   5.171545  0.143493\n",
       "...         ...      ...       ...           ...        ...       ...\n",
       "overweigh     1        9  0.000013  75721.000000  16.208406  0.000214\n",
       "pledge        1        6  0.000013  75721.000000  16.208406  0.000214\n",
       "salvation     1        9  0.000013  75721.000000  16.208406  0.000214\n",
       "timorous      1        8  0.000013  75721.000000  16.208406  0.000214\n",
       "thinks        1        6  0.000013  75721.000000  16.208406  0.000214\n",
       "\n",
       "[6965 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franky.VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chap_id', 'para_num', 'sent_num', 'token_num']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franky.OHCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = franky.gather_tokens(2).sent_str.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to mrs',\n",
       " 'saville england',\n",
       " '',\n",
       " 'st',\n",
       " 'petersburgh dec',\n",
       " '11th 17',\n",
       " 'you will rejoice to hear that no disaster has accompanied the commencement of an enterprise which you have regarded with such evil forebodings',\n",
       " 'i arrived here yesterday',\n",
       " 'and my first task is to assure my dear sister of my welfare and increasing confidence in the success of my undertaking',\n",
       " 'i am already far north of london']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = franky.VOCAB.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'i', 'of', 'to', 'my', 'a', 'in', 'was', 'that']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = NgramCounter(sents, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>mle</th>\n",
       "      <th>mle2</th>\n",
       "      <th>p</th>\n",
       "      <th>log_p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>-10.445015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11th</th>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-11.181980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-11.181980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12th</th>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-11.181980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-11.181980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">youthful</th>\n",
       "      <th>days</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-11.182394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovers</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>-10.445429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">zeal</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-11.182808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modern</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-11.182808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>-10.445843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40804 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 n       mle      mle2         p      log_p\n",
       "w0       w1                                                \n",
       "1        </s>    2  0.000022  1.000000  0.000717 -10.445015\n",
       "11th     17      1  0.000011  0.500000  0.000430 -11.181980\n",
       "         the     1  0.000011  0.500000  0.000430 -11.181980\n",
       "12th     17      1  0.000011  0.500000  0.000430 -11.181980\n",
       "         </s>    1  0.000011  0.500000  0.000430 -11.181980\n",
       "...             ..       ...       ...       ...        ...\n",
       "youthful days    1  0.000011  0.333333  0.000430 -11.182394\n",
       "         lovers  2  0.000022  0.666667  0.000717 -10.445429\n",
       "zeal     </s>    1  0.000011  0.250000  0.000430 -11.182808\n",
       "         modern  1  0.000011  0.250000  0.000430 -11.182808\n",
       "         of      2  0.000022  0.500000  0.000717 -10.445843\n",
       "\n",
       "[40804 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.LM[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.LM[2].n.unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "List six words that precede the word \"monster,\" excluding stop words (and sentence boundary markers). Stop words include 'a', 'an', 'the', 'this', 'that', etc.\n",
    "\n",
    "Hint, use the `df.query()` method.\n",
    "\n",
    "**<span style=\"color:red;\">ISSUE</span>**: If you use `text_importer.py` you get a set of 6, if you parse it yourself you get 5 of the same but a different 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>mle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th>monster</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abhorred</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detestable</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gigantic</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hellish</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hideous</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miserable</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <th>monster</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n       mle\n",
       "w0         w1                   \n",
       "<s>        monster   1  0.000011\n",
       "a          monster   3  0.000033\n",
       "abhorred   monster   1  0.000011\n",
       "detestable monster   1  0.000011\n",
       "gigantic   monster   1  0.000011\n",
       "hellish    monster   1  0.000011\n",
       "hideous    monster   1  0.000011\n",
       "miserable  monster   1  0.000011\n",
       "the        monster  20  0.000220\n",
       "this       monster   1  0.000011"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.LM[1].query(\"w1 == 'monster'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "abhorred\n",
    "detestable    \n",
    "gigantic      \n",
    "hellish       \n",
    "hideous       \n",
    "miserable     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying it by hand ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_line = open(src_file_path, 'r').read()\n",
    "big_line = big_line.lower().replace(\"\\n\", ' ')\n",
    "big_line = re.sub(r\"[\\W_]+\", \" \", big_line)\n",
    "big_line = re.sub(r\"\\s+\", \" \", big_line)\n",
    "tokens = big_line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the project gutenberg ebook of frankenstein by mary w shelley this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or re use it under the terms of the project gutenberg license included with this ebook or online at www gutenberg org title frankenstein or the modern prometheus author mary w shelley release date march 13 2013 ebook 42324 language english start of this project gutenberg ebook frankenstein produced by greg w'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_line[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_data = []\n",
    "for i in range(len(tokens)):\n",
    "    bg_data.append(tokens[i:i+2])\n",
    "BG = pd.DataFrame(bg_data, columns=['w0','w1']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40878</th>\n",
       "      <td>a</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33259</th>\n",
       "      <td>abhorred</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48760</th>\n",
       "      <td>cried</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45661</th>\n",
       "      <td>detestable</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72064</th>\n",
       "      <td>gigantic</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70652</th>\n",
       "      <td>hellish</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48800</th>\n",
       "      <td>hideous</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18370</th>\n",
       "      <td>miserable</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19663</th>\n",
       "      <td>the</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19350</th>\n",
       "      <td>this</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               w0       w1\n",
       "40878           a  monster\n",
       "33259    abhorred  monster\n",
       "48760       cried  monster\n",
       "45661  detestable  monster\n",
       "72064    gigantic  monster\n",
       "70652     hellish  monster\n",
       "48800     hideous  monster\n",
       "18370   miserable  monster\n",
       "19663         the  monster\n",
       "19350        this  monster"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BG.query(\"w1 == 'monster'\").sort_values('w0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 \n",
    "\n",
    "List the following sentences in ascending order of bigram perpexity according to the language model generated from the text.\n",
    "\n",
    "```\n",
    "The monster is on the ice.\n",
    "Flowers are happy things.\n",
    "I have never seen the aurora borealis.\n",
    "He never knew the love of a family.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NgramLanguageModel(train)\n",
    "model.apply_smoothing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = \"\"\"\n",
    "The monster is on the ice.\n",
    "Flowers are happy things.\n",
    "I have never seen the aurora borealis.\n",
    "He never knew the love of a family.\n",
    "\"\"\".split('\\n')[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = [s.lower() for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = NgramCounter(test_sents, vocab)\n",
    "test.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "      <th>len</th>\n",
       "      <th>ng_1_ll</th>\n",
       "      <th>pp1</th>\n",
       "      <th>ng_2_ll</th>\n",
       "      <th>pp2</th>\n",
       "      <th>ng_3_ll</th>\n",
       "      <th>pp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the monster is on the ice.</td>\n",
       "      <td>9</td>\n",
       "      <td>-46.649460</td>\n",
       "      <td>36.334631</td>\n",
       "      <td>-74.688657</td>\n",
       "      <td>314.897754</td>\n",
       "      <td>-213.042107</td>\n",
       "      <td>1.335934e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flowers are happy things.</td>\n",
       "      <td>7</td>\n",
       "      <td>-44.532783</td>\n",
       "      <td>82.243297</td>\n",
       "      <td>-75.997581</td>\n",
       "      <td>1854.477868</td>\n",
       "      <td>-177.397939</td>\n",
       "      <td>4.254725e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have never seen the aurora borealis.</td>\n",
       "      <td>10</td>\n",
       "      <td>-50.323281</td>\n",
       "      <td>32.725155</td>\n",
       "      <td>-87.041808</td>\n",
       "      <td>417.080128</td>\n",
       "      <td>-230.966554</td>\n",
       "      <td>8.969869e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he never knew the love of a family.</td>\n",
       "      <td>11</td>\n",
       "      <td>-65.633527</td>\n",
       "      <td>62.538999</td>\n",
       "      <td>-115.580343</td>\n",
       "      <td>1455.504786</td>\n",
       "      <td>-232.560952</td>\n",
       "      <td>2.313915e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sent_str  len    ng_1_ll        pp1  \\\n",
       "0              the monster is on the ice.    9 -46.649460  36.334631   \n",
       "1               flowers are happy things.    7 -44.532783  82.243297   \n",
       "2  i have never seen the aurora borealis.   10 -50.323281  32.725155   \n",
       "3     he never knew the love of a family.   11 -65.633527  62.538999   \n",
       "\n",
       "      ng_2_ll          pp2     ng_3_ll           pp3  \n",
       "0  -74.688657   314.897754 -213.042107  1.335934e+07  \n",
       "1  -75.997581  1854.477868 -177.397939  4.254725e+07  \n",
       "2  -87.041808   417.080128 -230.966554  8.969869e+06  \n",
       "3 -115.580343  1455.504786 -232.560952  2.313915e+06  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.T.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                the monster is on the ice.\n",
       "2    i have never seen the aurora borealis.\n",
       "3       he never knew the love of a family.\n",
       "1                 flowers are happy things.\n",
       "Name: sent_str, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.T.S.sort_values('pp2').sent_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "Using the bigram model represented as a matrix, explore the relationship between bigram pairs as done in the \"Explore\" section of the template notebook, but use the following lists. **What might you speculate about gender and communication given the results you see?**\n",
    "* `['he','she']` to select the indices.\n",
    "* `['said','heard']` to select the columns.\n",
    "\n",
    "Hint: use `.unstack()` method on the feature `n` and then use `.loc[]` to select the first list from the index, and the second list from the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGX = model.LM[1].n.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1   said  heard\n",
      "w0              \n",
      "he   21.0    5.0\n",
      "she   3.0    3.0\n"
     ]
    }
   ],
   "source": [
    "print(BGX.loc[['he','she'],['said','heard']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speculation: Men talk more than women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Generate a text using the `generate_text` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. I REMEMBERED SHUDDERING THE MAD ENTHUSIASM THAT HURRIED ME ON EVERY SIDE THE SOUND OF VOICES AS THE CASE I DARE NOT.\n",
      "\n",
      "02. BUT SUCCESS SHALL CROWN MY ENDEAVOURS SO SOON.\n",
      "\n",
      "03. AND IF THEIR TESTIMONY SHALL NOT.\n",
      "\n",
      "04. THEY DIED BY MY PROTECTORS HAD MANIFESTED TOWARDS HIM.\n",
      "\n",
      "05. A DEADLY STRUGGLE WOULD THEN DRIVE AWAY INCIPIENT DISEASE.\n",
      "\n",
      "06. BUT SLEEP DID NOT ALLOW ME TO WRITE TO YOU FIRST SAW HIM SOMETIMES SHUDDER WITH HORROR.\n",
      "\n",
      "07. BUT AS I DID NOT LIVE TO FULFIL IT.\n",
      "\n",
      "08. HE ASKED ME WITH AFFECTION WAS THE CORPSE OF SOME DISCOVERIES HAVING BEEN MADE BY DIFFERENT FEELINGS.\n",
      "\n",
      "09. BEFORE I LOOKED UPON ME HOWEVER WITH SOME DEGREE BENEFICIAL.\n",
      "\n",
      "10. EVERY ONE WAS NEAR ME WHO SOOTHED ME.\n",
      "\n",
      "11. AND ALTHOUGH THE STRANGER.\n",
      "\n",
      "12. AND I CONJECTURED TO REST IF THERE WAS NO LONGER NECESSARY AND YET SHE PAID THE GREATEST DANGER OWING TO THE ACTIVE SPIRIT OF GOOD.\n",
      "\n",
      "13. .\n",
      "\n",
      "14. HIS MANNERS WERE RUDE DESERVED BETTER TREATMENT THAN BLOWS AND A WINNING MILDNESS TO HER.\n",
      "\n",
      "15. .\n",
      "\n",
      "16. WHEN I MOMENTARILY EXPECT MY RELEASE IS THE DEVOURING AND ONLY PASSION OF MY NERVOUS SYMPTOMS.\n",
      "\n",
      "17. BUT MY TOILS.\n",
      "\n",
      "18. I REMAINED IN THE COLLECTIONS AT SERVOX AND CHAMOUNIX.\n",
      "\n",
      "19. THE HUMAN FRAME COULD NO LONGER AT A DISTANCE AND FORMED THE UTMOST SELF VIOLENCE I CURBED THE IMPERIOUS VOICE OF MY IMAGINATION THAN I LOVED AND SORROWING FRIENDS.\n",
      "\n",
      "20. THE RAIN AGAIN BEGAN TO MOVE MY ICE RAFT WHICH LAY CLOSE TO MY HOME MY FIRST DUTIES ON MY ANIMAL STRIVING SO TO FORGET THOSE FRIENDS WHO WERE SO MANY MISFORTUNES WEIGH UPON YOU.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.generate_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "Compute the redundancy $R$ for each of the n-gram models using the MLE of the joint probability of each ngram type. In other words, for each model, just use the `.mle` feature as $p$ in computing $H = \\sum p(ng) \\log_2(1/p(ng))$\n",
    "\n",
    "Remember that $R = 1 - \\frac{H}{H_{max}}$, where $H$ is the actual entropy of the model and $H_{max}$ is its maximum entropy. \n",
    "\n",
    "Does $R$ increase, decrease, or remain the same as the choice of n-gram increases in length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = []\n",
    "for i in range(3):\n",
    "    N = V**(i+1)\n",
    "    H = (train.LM[i]['mle'] * np.log2(1/train.LM[i]['mle'])).sum()\n",
    "    Hmax = np.log2(N)\n",
    "    R.append(int(round(1 - H/Hmax, 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 48, 61]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: Redundancy increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red;\">ISSUE</span>**: If you use the just the vector length of seen values, the redundancy will decrease. We accept both answers since some \n",
    "students were told to use only the seen values for the length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "```\n",
    "self.T.S[f'ng_{ng}_ll'] = self.T.NG[i]\\\n",
    "    .join(self.LM[i].log_p, on=self.widx[:ng])\\\n",
    "    .fillna(self.Z1[i]).fillna(self.Z2[i])\\\n",
    "    .groupby('sent_num').log_p.sum()\n",
    "    \n",
    "self.T.S[f'pp{ng}'] = 2**( -self.T.S[f'ng_{ng}_ll'] / self.T.S['len'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram Prediction \n",
    "X = test.NG[1]\\\n",
    "    .join(train.LM[1].log_p, on=['w0','w1'])\\\n",
    "    .fillna(model.Z1[1])\\\n",
    "    .fillna(model.Z2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent_num\n",
       "0    -74.688657\n",
       "1    -75.997581\n",
       "2    -87.041808\n",
       "3   -115.580343\n",
       "Name: log_p, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.groupby('sent_num').log_p.sum() #.sort_values(ascending=False).to_frame('log_p_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -74.688657\n",
       "1    -75.997581\n",
       "2    -87.041808\n",
       "3   -115.580343\n",
       "Name: ng_2_ll, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.S.ng_2_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS5559_LMs.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235.517px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
